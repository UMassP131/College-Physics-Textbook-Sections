<?xml version="1.0"?>
<document xmlns="http://cnx.rice.edu/cnxml" id="imported-from-openoffice" module-id="imported-from-openoffice" cnxml-version="0.7">
  <title>Why Entropy is Logarithmic</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml" mdml-version="0.5">
  <!-- WARNING! The 'metadata' section is read only. Do not edit below.
       Changes to the metadata section in the source will not be saved. -->
  <md:repository>https://legacy.cnx.org/content</md:repository>
  <md:content-id>new</md:content-id>
  <md:title>Why Entropy is Logarithmic</md:title>
  <md:version>**new**</md:version>
  <md:created>2017/07/20 14:01:19.274 GMT-5</md:created>
  <md:revised>2017/07/20 14:01:19.355 GMT-5</md:revised>
  <md:actors>
    <md:person userid="davidnvn">
      <md:firstname>David</md:firstname>
      <md:surname>Nguyen</md:surname>
      <md:fullname>David Nguyen</md:fullname>
      <md:email>dnguyen@umass.edu</md:email>
    </md:person>
  </md:actors>
  <md:roles>
    <md:role type="author">davidnvn</md:role>
    <md:role type="maintainer">davidnvn</md:role>
    <md:role type="licensor">davidnvn</md:role>
  </md:roles>
  <md:license url="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License 4.0</md:license>
  <!-- For information on license requirements for use or modification, see license url in the
       above <md:license> element.
       For information on formatting required attribution, see the URL:
         CONTENT_URL/content_info#cnx_cite_header
       where CONTENT_URL is the value provided above in the <md:content-url> element.
  -->
  <md:keywordlist>
    <md:keyword>umassphysics</md:keyword>
  </md:keywordlist>
  <md:subjectlist>
    <md:subject>Science and Technology</md:subject>
  </md:subjectlist>
  <md:abstract/>
  <md:language>en</md:language>
  <!-- WARNING! The 'metadata' section is read only. Do not edit above.
       Changes to the metadata section in the source will not be saved. -->
</metadata>

<content>

	<note id="copyright">The following is based off of <newline />umdberg / Why entropy is logarithmic. Available at:<link url="http://umdberg.pbworks.com/w/page/49691685/Why%20entropy%20is%20logarithmic."> http://umdberg.pbworks.com/w/page/49691685/Why%20entropy%20is%20logarithmic.</link> (Accessed: 20th July 2017)


</note>

    <para id="import-auto-idm203112544">We defined the entropy (<emphasis effect="italics">S</emphasis>) of a system as <emphasis effect="italics">k</emphasis><sub>B</sub> ln <emphasis effect="italics">W</emphasis>, where <emphasis effect="italics">W</emphasis> is the number of possible arrangements of the system.  But why?  Why not just say that entropy <emphasis effect="bold">is</emphasis> the number of arrangements?  Let's think through why it has to be defined this way.</para>
    <para id="import-auto-idm893033696">We want to define entropy as an <emphasis effect="bold">extensive property</emphasis>, i.e. if I have two systems A and B, the total entropy should be the entropy of A plus the entropy of B.  This is like mass (2 kg + 2 kg = 4 kg), and not an <emphasis effect="bold">intensive property </emphasis>like temperature (if you combine two systems that are each at 300 K, you have a system at 300 K, <emphasis effect="bold">not</emphasis> at 600 K!).</para>
    <para id="import-auto-idm1392856192">What happens to the number of possible arrangements when you combine two systems?  If system A can be in 3 different arrangements and system B can be in 5 different arrangements, then there are 3*5 = 15 possible combinations.  They multiply!  This '80s <link url="http://www.youtube.com/watch?v=w0i_ZFlGTVY">music video</link> explains why.</para>
    <para id="import-auto-idm906888128">So we can't just define entropy as the number of possible arrangements, because we need the entropy to <emphasis effect="bold">add</emphasis>, not <emphasis effect="bold">multiply</emphasis>, when we combine two systems.</para>
    <para id="import-auto-idm243949664">How do you turn multiplication into addition?  Just take the logarithm.  3 * 5 = 15, but ln 3 + ln 5 = ln 15.</para>
    <para id="import-auto-idm219169360">So that's why entropy is defined as a constant times ln <emphasis effect="italics">W</emphasis>.  <emphasis effect="italics">W</emphasis> (the number of arrangements) is a dimensionless number, so ln <emphasis effect="italics">W</emphasis> is too.</para>
    <para id="import-auto-idm1378530416">The constant out in front could be any constant, but we use Boltzmann's constant, 1.38 x 10<sup>-23</sup> J/K.  When we get to Gibbs free energy, we'll see that this constant has the right units, since we need entropy to be in units of energy/temperature.</para>
    <para id="import-auto-idm1880638864">Ben Dreyfus 1/9/2012</para>
  </content>
</document>
