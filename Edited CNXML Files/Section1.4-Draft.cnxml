<?xml version="1.0"?>
<document xmlns="http://cnx.rice.edu/cnxml" id="imported-from-openoffice" module-id="imported-from-openoffice" cnxml-version="0.7">
  <title>1.4 Introduction to Statistics</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml"
          mdml-version="0.5">
  <!-- WARNING! The 'metadata' section is read only. Do not edit below.
       Changes to the metadata section in the source will not be saved. -->
  <md:repository>https://legacy.cnx.org/content</md:repository>
  <md:content-id>new</md:content-id>
  <md:title>1.4 Introduction to Statistics</md:title>
  <md:version>**new**</md:version>
  <md:created>2017/05/24 13:11:29.805 GMT-5</md:created>
  <md:revised>2017/05/24 13:11:30.793 GMT-5</md:revised>
  <md:actors>
    <md:person userid="davidnvn">
      <md:firstname>David</md:firstname>
      <md:surname>Nguyen</md:surname>
      <md:fullname>David Nguyen</md:fullname>
      <md:email>dnguyen@umass.edu</md:email>
    </md:person>
  </md:actors>
  <md:roles>
    <md:role type="author">davidnvn</md:role>
    <md:role type="maintainer">davidnvn</md:role>
    <md:role type="licensor">davidnvn</md:role>
  </md:roles>
  <md:license url="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License 4.0</md:license>
  <!-- For information on license requirements for use or modification, see license url in the
       above <md:license> element.
       For information on formatting required attribution, see the URL:
         CONTENT_URL/content_info#cnx_cite_header
       where CONTENT_URL is the value provided above in the <md:content-url> element.
  -->
  <md:keywordlist>
    <md:keyword>Physics</md:keyword>
    <md:keyword>Statistics</md:keyword>
  </md:keywordlist>
  <md:subjectlist>
    <md:subject>Science and Technology</md:subject>
  </md:subjectlist>
  <md:abstract></md:abstract>
  <md:language>en</md:language>
  <!-- WARNING! The 'metadata' section is read only. Do not edit above.
       Changes to the metadata section in the source will not be saved. -->
</metadata>

<content>

<exercise id="inotei" type="check-understanding"><label/><title><media id="inoteii" alt="the umass logo" display="inline"><image mime-type="image/png" src="umass-logo5.png" width="300" print-width="3in"/></media></title><problem id="inoteip"><para id="inoteipp"><list id="quiz">
			<title>Your Quiz would Cover</title>
			<item>Mean and Standard Deviation: Know the definition of both of these as well as how to calculate them for a given data set.</item>
			<item>Using mean and standard deviation in calculations.</item>
		</list></para></problem></exercise>

		 <para id="import-auto-idm246397648">This section focuses on some basic statistics facts that we will need for this class. This section is also available as a video. <newline /><emphasis effect="italics">Link to the video: </emphasis><link url="https://www.youtube.com/watch?v=sGjq350QY7c" window="new">https://www.youtube.com/watch?v=sGjq350QY7c</link></para>
	
    <section id="import-auto-idm221767392">
      <title>How to present data for laboratory exerciese</title>
      <para id="import-auto-idm869886496">How do people actually present data? A common method is μ ± σ, where μ is the <emphasis>mean</emphasis>, and σ is the <emphasis>standard deviation</emphasis>. Before we talk about mean and standard deviation, we have to discuss a little bit about measurement. Most objects have some variation. People come in a variety of heights, for example, and even manufactured objects like, say pencils, will have a variety of lengths. If you can measure them precisely enough, this variation may be very small, for objects made by machines for example, but it will still be there. Another example that’s not just lengths or heights is the number of blood cells passing through a capillary per second. This quantity will, of course, vary from second to second. Another example might be that if you have a spring based launcher of a ball, the ball will travel slightly different distances each time, if for no other reason than the spring coils slightly different ways on the molecular level with each launch. These types of variation are intrinsic, and result in variation in your measurement. However, sometimes measuring something directly is tough, and you need to use indirect methods, like we do for our library lab. One way to get a feel for the precision of your method is to make the measurement with a few different methods, with what we expect to have similar levels of precision. The variation in the results of the different methods can give a sense of the precision of your measurements; this is how we will evaluate our methods for the library lab. </para>
    </section>
    <section id="import-auto-idm253364208">
      <title>Mean and Standard Deviation</title>
      <para id="import-auto-idm248770832">To talk about the ideas of mean and standard deviation, it’s helpful to have an example. Say we took the height of 20 men from the United States and presented the data in the table below.</para>
      <table id="import-auto-idm238379744" summary="">
        <tgroup cols="2">
          <colspec colnum="1" colname="c1"/>
          <colspec colnum="2" colname="c2"/>
          <thead>
            <row>
              <entry>
                <emphasis effect="bold">Person</emphasis>
              </entry>
              <entry>
                <emphasis effect="bold">Height [ cm]</emphasis>
              </entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>1</entry>
              <entry>177.7</entry>
            </row>
            <row>
              <entry>2</entry>
              <entry>181.4</entry>
            </row>
            <row>
              <entry>3</entry>
              <entry>179.4</entry>
            </row>
            <row>
              <entry>4</entry>
              <entry>164.9</entry>
            </row>
            <row>
              <entry>5</entry>
              <entry>180.4</entry>
            </row>
            <row>
              <entry>6</entry>
              <entry>174.0</entry>
            </row>
            <row>
              <entry>7</entry>
              <entry>178.6</entry>
            </row>
            <row>
              <entry>8</entry>
              <entry>176.1</entry>
            </row>
            <row>
              <entry>9</entry>
              <entry>181.9</entry>
            </row>
            <row>
              <entry>10</entry>
              <entry>179.7</entry>
            </row>
            <row>
              <entry>11</entry>
              <entry>175.8</entry>
            </row>
            <row>
              <entry>12</entry>
              <entry>175.0</entry>
            </row>
            <row>
              <entry>13</entry>
              <entry>180.9</entry>
            </row>
            <row>
              <entry>14</entry>
              <entry>181.9</entry>
            </row>
            <row>
              <entry>15</entry>
              <entry>181.0</entry>
            </row>
            <row>
              <entry>16</entry>
              <entry>180.5</entry>
            </row>
            <row>
              <entry>17</entry>
              <entry>169.2</entry>
            </row>
            <row>
              <entry>18</entry>
              <entry>173.3</entry>
            </row>
            <row>
              <entry>19</entry>
              <entry>171.8</entry>
            </row>
            <row>
              <entry>20</entry>
              <entry>176.5</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <para id="import-auto-idm253178384"> Note that there are no uncertainties listed in this table. Yes, the ruler that we’re using has some limit of precision, which is apparently .1 cm according to this table, but the variation between measurements is much larger than this, so the precision of the ruler won’t be too important. In a well-designed experiment the precision of your instruments should be much less than the intrinsic variation that you are trying to measure. </para>
      <section id="import-auto-idm247992880">
        <title>Mean</title>
        <para id="import-auto-idm218537600">The most complete way to report this data would be to report the entire table as we’ve done here. However, this becomes impractical as more and more data are collected. Moreover, it becomes very difficult to see trends when you just got big lists of numbers. Therefore, we need ways to characterize our data. If you’re looking for a way to characterize the data, the first thing that you might think of to do would be to take the average. Now in mathematics, the word average is replaced with the word mean; they’re synonyms. There are many different symbols for mean and each discipline seems to have their own one, so I’m going to present you with all of them. I wish we could agree on which symbol to use, but we can’t, so I’m just going to show you all of what’s out there. The Greek letter <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mi>µ</m:mi><m:annotation encoding="StarMath 5.0">µ</m:annotation></m:semantics></m:math> here is a very general symbol for mean. A general tip I would have is that you learn your Greek alphabet. Another way to represent mean is, let’s say we’re using the variable <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mi>H</m:mi><m:annotation encoding="StarMath 5.0">H</m:annotation></m:semantics></m:math> to represent the height of a man, then you might see <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mover accent="true"><m:mi>H</m:mi><m:mo>¯</m:mo></m:mover><m:annotation encoding="StarMath 5.0">overline {H}</m:annotation></m:semantics></m:math> or <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mrow><m:mo fence="true" stretchy="true">⟨</m:mo><m:mrow><m:mi>H</m:mi></m:mrow><m:mo fence="true" stretchy="true">⟩</m:mo></m:mrow><m:annotation encoding="StarMath 5.0">left langle H right rangle</m:annotation></m:semantics></m:math> to represent the mean. The formula for the mean is given by</para>
        <para id="import-auto-idm870760560">
          <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="block">
            <m:semantics>
              <m:mrow>
                <m:mrow>
                  <m:mi>μ</m:mi>
                  <m:mo stretchy="false">=</m:mo>
                  <m:mfrac>
                    <m:mn>1</m:mn>
                    <m:mi>N</m:mi>
                  </m:mfrac>
                </m:mrow>
                <m:mrow>
                  <m:munder>
                    <m:mo stretchy="false">∑</m:mo>
                    <m:mi>i</m:mi>
                  </m:munder>
                  <m:msub>
                    <m:mi>x</m:mi>
                    <m:mi>i</m:mi>
                  </m:msub>
                </m:mrow>
              </m:mrow>
              <m:annotation encoding="StarMath 5.0">μ= {1} over {N} sum from {i} {{x} rsub {i}}</m:annotation>
            </m:semantics>
          </m:math>
        </para>
        <para id="import-auto-idm1327170720">Many of the equations that you might see in this section can get pretty ugly looking, but they are manageable if you stop and parse them down and read what the equation is trying to tell you. A good tip for questions is to read actually right to left. So, let’s give that a shot with this equation. The letter <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mi>i</m:mi><m:annotation encoding="StarMath 5.0">i </m:annotation></m:semantics></m:math> represents an index over the measurements. Here we have 20 measurements, so <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mi>i</m:mi><m:annotation encoding="StarMath 5.0">i</m:annotation></m:semantics></m:math> is an integer that runs from 1 to 20. <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:msub><m:mi>x</m:mi><m:mi>i</m:mi></m:msub><m:annotation encoding="StarMath 5.0">{x} rsub {i}</m:annotation></m:semantics></m:math> is one specific measurement, so <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:msub><m:mi>x</m:mi><m:mn>5</m:mn></m:msub><m:annotation encoding="StarMath 5.0">{x} rsub {5}</m:annotation></m:semantics></m:math> is the height of the fifth person which, according to our table, is 180.4 cm. To calculate the mean, we add up all the measurements, and then divide by the number of measurements. Let’s calculate the mean. For these data, when we add up all of the measurements, we get a sum of 3540 cm. We divide by the number of measurements; take <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mfrac><m:mrow><m:mn>3540</m:mn><m:mi mathvariant="italic">cm</m:mi></m:mrow><m:mrow><m:mn>20</m:mn><m:mi mathvariant="italic">cm</m:mi></m:mrow></m:mfrac><m:annotation encoding="StarMath 5.0">{3540cm} over {20cm}</m:annotation></m:semantics></m:math>, which gives us a result of 177 cm. This is our average or mean.</para>
      </section>
      <section id="import-auto-idm211300000">
        <title>Standard Deviation</title>
        <para id="import-auto-idm247324720">The mean provides a great starting point for characterizing data, but it’s insufficient because it’s missing a key feature. Just representing the mean gives us no clue on how spread out these data are. Phrased differently, we don’t have any information on what is the average distance for a random data point to the mean. So if we’re looking at this question, let’s try to translate this question into mathematics. Well, the distance from a given data point <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:msub><m:mi>x</m:mi><m:mi>i</m:mi></m:msub><m:annotation encoding="StarMath 5.0">{x} rsub {i}</m:annotation></m:semantics></m:math> to the mean would be <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mrow><m:mrow><m:mo fence="true" stretchy="true">⟨</m:mo><m:mrow><m:mi>H</m:mi></m:mrow><m:mo fence="true" stretchy="true">⟩</m:mo></m:mrow><m:mo stretchy="false">−</m:mo><m:msub><m:mi>x</m:mi><m:mi>i</m:mi></m:msub></m:mrow><m:annotation encoding="StarMath 5.0">left langle H right rangle - {x} rsub {i}</m:annotation></m:semantics></m:math>, and the average distance would be, well, take all of these different distances, <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mrow><m:mi>μ</m:mi><m:mo stretchy="false">−</m:mo><m:msub><m:mi>x</m:mi><m:mi>i</m:mi></m:msub></m:mrow><m:annotation encoding="StarMath 5.0">μ- {x} rsub {i}</m:annotation></m:semantics></m:math>, add them all up and divide by the number of measurements. </para>
        <para id="import-auto-idm246042432">However, this idea has a problem. Some distances are lower than the mean. For example, person 6 is slightly shorter than our average. So, his distance to the mean will be positive, while some people are taller than the average, for example person 2, so their distance to the mean will be negative. If I add up positive numbers and negative numbers, I’ll probably get a result that’s very close to zero due to the cancellation. So how can we get around this problem? Well, you might think absolute values, but for calculus reasons, absolute values have some problems, so a better way to get around having negative numbers is to look at squaring them, because no matter what, when I take a number and square it, the result is positive. So, let’s look at the average squared distance from the mean. Mathematically, the average squared distance from the mean would be, take the distance from the data point to the mean, just mean minus data point, square it, add them all up and divide by the number of measurements. </para>
		
 <para xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:q="http://cnx.rice.edu/qml/1.0" xmlns:data="http://www.w3.org/TR/html5/dom.html#custom-data-attribute" id="import-auto-idm438928304"><m:math display="block">
            <m:semantics>
              <m:mrow>
                <m:msup>
                  <m:mn>&#963;</m:mn>
                  <m:mn>2</m:mn>
                </m:msup>
<m:mo stretchy="false">=</m:mo>
                <m:mfrac>
                  <m:mn>1</m:mn>
                  <m:mi>n</m:mi>
                </m:mfrac>
                <m:mrow>
                  <m:munderover>
                    <m:mo stretchy="false">&#8721;</m:mo>
                    <m:mi>i</m:mi>
                    <m:mi>n</m:mi>
                  </m:munderover>
                  <m:mrow>
					<m:mn>(</m:mn>
                    <m:msub>
                      <m:mi>x</m:mi>
                      <m:mi>i</m:mi>
                    </m:msub>
					<m:mo stretchy="false">-</m:mo>					
					<m:mi>&#956;</m:mi>
                    <m:msup>
                      <m:mn>)</m:mn>
                      <m:mn>2</m:mn>
                    </m:msup>
                  </m:mrow>
                </m:mrow>
              </m:mrow>
              <m:annotation encoding="StarMath 5.0">&lt;?&gt; ^ &lt;?&gt;  &lt;?&gt; over &lt;?&gt; sum from &lt;?&gt; to &lt;?&gt; {&lt;?&gt; rsub &lt;?&gt;  &lt;?&gt; ^ &lt;?&gt;}</m:annotation>
            </m:semantics>
          </m:math>
        </para>
		
        <para id="import-auto-idm252133040">Now all the numbers being added are positive, so there’s no cancellation. This quantity is called the variance, and we will label it with the variable <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:msup><m:mi>σ</m:mi><m:mn>2</m:mn></m:msup><m:annotation encoding="StarMath 5.0">{σ} ^ {2}</m:annotation></m:semantics></m:math>, for reasons that will become apparent in a moment. Let’s calculate the variance for this data. Again, variance is kind of an ugly formula, so you really got to slow down and take it one piece at a time. So let’s take an entry <emphasis effect="italics">i</emphasis>=1 and what do we do, take the entry and subtract it from the mean. This for <emphasis effect="italics">i</emphasis>=1 is -0.7 cm. We repeat this for all of our data. We get these results. Next in variance, we see we should square so for <emphasis effect="italics">i</emphasis>=1 the result is .49 cm<sup>2</sup>. I want to point out that we’ve now moved from cm to cm<sup>2</sup>, because when you square a number with units, you got to square the units too, and when we repeat it for all of our data and get these results to calculate variance, we take all of these numbers and add them up, which gives us 403.5  cm2. To get the variance divided by the number of measurements, which in this case is 20 giving us a variance of 20.2 cm<sup>2</sup>. </para>
        
		<para id="import-auto-idm212167904">Now variance has different units than mean, as we’ve already seen. The mean for this data set is 177.0 cm while the variance is 20.2 cm <sup>2</sup>. It’s very difficult to compare numbers with different units. To deal with this we, instead of looking at the variance, look at the standard deviation, which we represent by <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mi>σ</m:mi><m:annotation encoding="StarMath 5.0"> σ</m:annotation></m:semantics></m:math>. So, the standard deviation is the square root of the variance. This is why we represent variance with a <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:msup><m:mi>σ</m:mi><m:mn>2</m:mn></m:msup><m:annotation encoding="StarMath 5.0">{σ} ^ {2}</m:annotation></m:semantics></m:math>. In this example to get the standard deviation, we take square root of the variance so the square root of 20.2 cm<sup>2</sup>, to give us 4.49 cm. Now we have two quantities that are both in cm, and allows us to compare them.</para> 
		<para id="newpara">So how do we report numbers in the laboratory exercises? In this class, most of the labs in this course will have multiple measurements. We can use these different trials to calculate a mean and a standard deviation, and we can use this standard deviation as an uncertainty and use it to tell us how many decimals we should record. In our height example, we had a mean of 177 cm and a standard deviation a 4.49 cm. An appropriate way to represent this result would be 177 plus or minus 4.5 cm. This representation has a lot of advantages; it represents the average 177, and we have the standard deviation, which gives the person reading the number a sense of the spread of the data, and we have a reasonable number of digits. I’ve gone with one digit past the decimal point, and I did this based upon the standard deviation. While our standard deviation is officially 4.49, I rounded it to 4.5, because .01 is very small relative to our standard deviation, so I can’t really trust that .01. So while I removed some certainty of nice hard sig-fig rules, this is how numbers are actually reported in research, and this is how we’ll do it in class. Part of the point of the laboratory exercises to get you some experience with this sort of usage.</para>
      </section>
	  
	  <note><label/>The following section is based upon:<newline /> Denker, J. Uncertainty as Applied to Measurements and Calculations. Uncertainty as Applied to Measurments and Calculations (2011). Available at: <link url="http://www.av8n.com/physics/uncertainty.htm">http://www.av8n.com/physics/uncertainty.htm</link>. (Accessed: 26th August 2016)
	</note>
	  
	  <section id="import-auto-idm298879552">
      <title>Incorporating Mean and Standard Deviation into Calculations - Crank Three Times</title>
      <para id="import-auto-idm822865216">Here’s a simple yet powerful way of estimating the uncertainty of a result, given the uncertainty of the thing(s) it depends on.</para>
      <para id="import-auto-idm1148736208">Here’s the procedure, in the simple case when there is only one input variable with appreciable uncertainty:</para>
      <list id="import-auto-idm349074368" list-type="enumerated" number-style="lower-alpha">
        <item>Set up the calculation. Do it once in the usual way, using the nominal, best-estimate values for all the input variables.</item>
        <item>Then re-do the calculation with the uncertain variable at the end of its upper error bar.</item>
        <item>Then re-do the calculation with the uncertain variable at the end of its lower error bar.</item>
      </list>
      <para id="import-auto-idm1154002416">I call this the <emphasis effect="italics">Crank Three Times </emphasis>method. Here is an example:</para>
	  
	  <table id="crankthreetimes" summary="crank three times example"><label/>
		<tgroup cols="2">
			<tbody>
				<row>
					<entry>x</entry>
					<entry><m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mfrac><m:mi mathvariant="normal">1</m:mi><m:mi mathvariant="normal">x</m:mi></m:mfrac><m:annotation encoding="StarMath 5.0">&lt;?&gt; over &lt;?&gt;</m:annotation></m:semantics></m:math></entry>
				</row>
				<row>
					<entry>2.02 (high case)</entry>
					<entry>.495</entry>
				</row>
				<row>
					<entry>2 (nominal case)</entry>
					<entry>.5</entry>
				</row>
				<row>
					<entry>1.98</entry>
					<entry>.505</entry>
				</row>
			</tbody>
		</tgroup>
	  </table>
      
      <para id="import-auto-idm1120543632">Equation 35 tells us that if <emphasis effect="italics">x</emphasis> is distributed according to <emphasis effect="italics">x</emphasis>=2±.02 then <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mfrac><m:mi mathvariant="normal">1</m:mi><m:mi mathvariant="normal">x</m:mi></m:mfrac><m:annotation encoding="StarMath 5.0">&lt;?&gt; over &lt;?&gt;</m:annotation></m:semantics></m:math> is distributed according to <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mfrac><m:mi mathvariant="normal">1</m:mi><m:mi mathvariant="normal">x</m:mi></m:mfrac><m:annotation encoding="StarMath 5.0">&lt;?&gt; over &lt;?&gt;</m:annotation></m:semantics></m:math>=.5±.005. The Crank Three Times method is by no means an exact error analysis. It is an approximation. The nice thing is that you can understand the nature of the approximation. One of the glories of the Crank Three Times method is that in cases where it doesn’t work, it will tell you it isn’t working, provided you listen to what it’s trying to tell you. If you get asymmetrical error bars, you need to investigate further. Something bad is happening, and you need to check closely to see whether it is a little bit bad or very, very bad.</para>
      <para id="import-auto-idm301100288">As far as I can tell, for every flaw that this method has, the sig-figs method has the same flaw plus others ... which means Crank Three Times is therefore superior.</para>
      <para id="import-auto-idm1105339248">Crank Three Times shouldn’t require more than a few minutes of labor. Once a problem is set up, turning the crank should take only a couple of minutes; if it takes longer than that you should have been doing it on a spreadsheet all along. And if you are using a spreadsheet, Crank Three Times is super-easy and super-quick.</para>
      <para id="import-auto-idm334249232">If you have <emphasis effect="italics">N</emphasis> variables that are (or might be) making a significant contribution to the uncertainty of the result, the Crank Three Times method could more precisely be called the Crank 2<emphasis effect="italics">N</emphasis>+1 Times method. Here’s the procedure: Set up the spreadsheet and wiggle each variable in turn, and see what happens. Wiggle them <emphasis effect="italics">one</emphasis> at a time, leaving the other <emphasis effect="italics">N</emphasis>−1 at their original, nominal values.</para>
      <para id="import-auto-idm1140955584">For example, let’s say you’re looking for the area of a rectangle, and the length and width of the rectangle are measured to be 5±.6 and 2±.4, respectively. Using <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mrow><m:mi>A</m:mi><m:mo stretchy="false">=</m:mo><m:mi mathvariant="italic">lw</m:mi></m:mrow><m:annotation encoding="StarMath 5.0">A=lw</m:annotation></m:semantics></m:math>, the nominal crank is 10 cm<sup>2</sup>. Wiggling the length results in 10±1.2 cm<sup>2</sup> and wiggling the width results in 10±2 cm<sup>2</sup>. Note that even though the width has a lower uncertainty associated with it, its uncertainty it creates in the result is higher than that of the length. </para>
      <para id="import-auto-idm354744416">If you are worried about what happens when two of the input variables are simultaneously at the ends of their error bars, you can check that case if you want. However, beware that if there are many variables, checking all the possibilities is exponentially laborious. Furthermore, it is improbable that many variables would simultaneously take on extreme values, and checking extreme cases can lead you to overestimate the uncertainty. For these reasons, and others, if you have numerous variables and need to study the system properly, at some point you need to give up on the Crank Three Timesmethod and do something more sophisticated called a Monte Carlo analysis which we will not discuss in this class. The Crank Three Times method can be considered an ultra-simplified variation of the Monte Carlo method, suitable for introductory reconnaissance.</para>
      <para id="import-auto-idm1094771904">In the <emphasis effect="italics">rare</emphasis> situation where you want a worst-case analysis, you can move each variable to whichever end of its error bar makes a positive contribution to the final answer, and then flip them all so that each one makes a negative contribution. In most cases, however, a worst-case analysis is wildly over-pessimistic, especially when there are more than a few uncertain variables.</para>
      <para id="import-auto-idm302015408">Remember: there are many cases, especially when there are multiple uncertain variables and/or correlations among the variables and/or nonlinearities for which you will need to be more sophisticated.. The Crank Three Times method can be considered an ultra-simplified variation of the Monte Carlo method, suitable for introductory reconnaissance.</para>
      <para id="import-auto-idm1239200464">Here is another example, which is more interesting because it exhibits nonlinearity:</para>
	  
	  <table id="crankthreetimes2" summary="crank three times example 2"><label/>
		<tgroup cols="2">
			<tbody>
				<row>
					<entry>x</entry>
					<entry><m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mfrac><m:mi mathvariant="normal">1</m:mi><m:mi mathvariant="normal">x</m:mi></m:mfrac><m:annotation encoding="StarMath 5.0">&lt;?&gt; over &lt;?&gt;</m:annotation></m:semantics></m:math></entry>
				</row>
				<row>
					<entry>2.9 (high case)</entry>
					<entry>.35</entry>
				</row>
				<row>
					<entry>2 (nominal case)</entry>
					<entry>.5</entry>
				</row>
				<row>
					<entry>1.1 (low case)</entry>
					<entry>.91</entry>
				</row>
			</tbody>
		</tgroup>
	  </table>
      
      <para id="import-auto-idm1129331104">Equation 36 tells us that if <emphasis effect="italics">x</emphasis> is distributed according to <emphasis effect="italics">x</emphasis>=2±.9 then <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mfrac><m:mi mathvariant="normal">1</m:mi><m:mi mathvariant="normal">x</m:mi></m:mfrac><m:annotation encoding="StarMath 5.0">&lt;?&gt; over &lt;?&gt;</m:annotation></m:semantics></m:math> is distributed according to<m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mrow><m:mfrac><m:mi mathvariant="normal">1</m:mi><m:mi mathvariant="normal">x</m:mi></m:mfrac><m:msubsup><m:mi mathvariant="normal">=5</m:mi><m:mi mathvariant="normal">+0.42</m:mi><m:mi mathvariant="normal">-0.16</m:mi></m:msubsup></m:mrow><m:annotation encoding="StarMath 5.0">&lt;?&gt; over &lt;?&gt;  &lt;?&gt; rsub &lt;?&gt; rsup &lt;?&gt;</m:annotation></m:semantics></m:math>. Even though the error bars on <emphasis effect="italics">x</emphasis>  are symmetric, the error bars on <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mfrac><m:mi mathvariant="normal">1</m:mi><m:mi mathvariant="normal">x</m:mi></m:mfrac><m:annotation encoding="StarMath 5.0">&lt;?&gt; over &lt;?&gt;</m:annotation></m:semantics></m:math> are markedly lopsided.</para>
      <para id="import-auto-idm336519728">Lopsided error bars are fairly common in practice. Sometimes they are merely a symptom of a harmless nonlinearity, but sometimes they are a symptom of something much worse. As an example, let’s say you had a calculation that was<m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mfrac><m:mi mathvariant="normal">1</m:mi><m:mi mathvariant="normal">x-2</m:mi></m:mfrac><m:annotation encoding="StarMath 5.0">&lt;?&gt; over &lt;?&gt;</m:annotation></m:semantics></m:math>, and the value of x was found to be 3±2.When you do the crank three times method, the nominal crank is 1, the upper crank is<m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mfrac><m:mn>1</m:mn><m:mn>3</m:mn></m:mfrac><m:annotation encoding="StarMath 5.0">{1} over {3}</m:annotation></m:semantics></m:math>, and the lower crank is -1. Both the upper and lower cranks give values less than the nominal; the result is<m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:msubsup><m:mn>1</m:mn><m:mrow><m:mo stretchy="false">−</m:mo><m:mn>2</m:mn></m:mrow><m:mrow><m:mrow><m:mo stretchy="false">−</m:mo><m:mn>2</m:mn></m:mrow><m:mo stretchy="false">/</m:mo><m:mn>3</m:mn></m:mrow></m:msubsup><m:annotation encoding="StarMath 5.0">{1} rsub {-2} rsup {-2/3}</m:annotation></m:semantics></m:math>, which doesn’t make much sense. The absurdity arises because at x=2, the function <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mfrac><m:mi mathvariant="normal">1</m:mi><m:mi mathvariant="normal">x-2</m:mi></m:mfrac><m:annotation encoding="StarMath 5.0">&lt;?&gt; over &lt;?&gt;</m:annotation></m:semantics></m:math> is equal to <m:math xmlns:m="http://www.w3.org/1998/Math/MathML" display="inline"><m:semantics><m:mfrac><m:mi mathvariant="normal">1</m:mi><m:mi mathvariant="normal">0</m:mi></m:mfrac><m:annotation encoding="StarMath 5.0">&lt;?&gt; over &lt;?&gt;</m:annotation></m:semantics></m:math> and the function is undefined, i.e. has a <emphasis effect="italics">singularity</emphasis><emphasis effect="bold"><emphasis effect="italics">. </emphasis></emphasis> Here’s a graph of the function and the data, which is the value of x and its uncertainty:</para>
      <figure id="import-auto-idm793760128"><label/>
        <media id="import-auto-idm320947488" alt="">
          <image mime-type="image/png" src="Picture 1.png" height="498" width="578"/>
        </media>
      </figure>
      <para id="import-auto-idm764262960">Notice that for all the values above the nominal value of x (indicated by the point), the function behaves normally, but for the values below, the function has a ‘break’ in it at x=2, where the function becomes a division by zero. Notice as well that the function spikes up around the point x=2 as well. If we were to continue the function as it approaches closer and closer to 2, we would see that the function would go up to infinity and to negative infinity, and infinite values tend to break uncertainty calculations. What the nonsense result is trying to tell you is that your error bars contain a problem point, such as the one above. Results such as these are the ones you should be wary of.</para>

    </section>
    </section>
  </content>
</document>
